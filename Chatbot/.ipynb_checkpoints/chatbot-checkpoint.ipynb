{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a79bae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'question', 'answer'], dtype='object')\n",
      "Index(['Unnamed: 0', 'question', 'answer'], dtype='object')\n",
      "Index(['Unnamed: 0', 'question', 'answer'], dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4772 entries, 0 to 3687\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4772 non-null   int64 \n",
      " 1   question    4772 non-null   object\n",
      " 2   answer      4772 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 149.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10103 entries, 0 to 2754\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  10103 non-null  int64 \n",
      " 1   MQ          10103 non-null  object\n",
      " 2   SA          10103 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 315.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14875 entries, 0 to 2754\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Q       14875 non-null  object\n",
      " 1   A       14875 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 348.6+ KB\n",
      "None\n",
      "임의 질문 샘플 정수 인코딩: [1202, 6, 2154, 375, 879, 2161, 7226, 8037, 206, 2807, 4947, 168]\n",
      "[8261  879 2161 1081 8240 8135 8193 1100 4834   38 8262    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "batch_size=64\n",
    "buffer_size=20000\n",
    "df1=pd.read_excel('1.xlsx')\n",
    "df2=pd.read_excel('3.xlsx')\n",
    "df3=pd.read_excel('6.xlsx')\n",
    "df4=pd.read_excel('11.xlsx')\n",
    "df5=pd.read_excel('12.xlsx')\n",
    "df6=pd.read_excel('13.xlsx')\n",
    "df7=pd.read_excel(\"qa1.xlsx\")\n",
    "print(df4.columns)\n",
    "print(df5.columns)\n",
    "print(df6.columns)\n",
    "df_medium1=pd.concat([df4,df5,df6])\n",
    "print(df_medium1.info())\n",
    "df_medium2=pd.concat([df1,df2,df3])\n",
    "print(df_medium2.info())\n",
    "df_medium1.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df_medium2.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "df_medium1.rename(columns={'question':'Q','answer':'A'},inplace=True)\n",
    "df_medium2.rename(columns={'MQ':'Q','SA':'A'},inplace=True)\n",
    "df_medium3=pd.concat([df_medium1,df_medium2])\n",
    "print(df_medium3.info())\n",
    "df_final=pd.concat([df_medium3,df7])\n",
    "df_final.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
    "question=[]\n",
    "answers=[]\n",
    "for sentence in df_final['Q']:\n",
    "    sentence=re.sub(r\"([?.!,])\",r\"\\1 \",sentence)\n",
    "    sentence=sentence.strip()\n",
    "    question.append(sentence)\n",
    "for sentence in df_final['A']:\n",
    "    sentence=re.sub(r\"([?.!,])\",r\"\\1 \",sentence)\n",
    "    sentence=sentence.strip()\n",
    "    answers.append(sentence)\n",
    "\n",
    "    \n",
    "# 정수 인코딩 & 단어 사전 형성\n",
    "tokenizer=tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(question+answers, target_vocab_size=2**13)\n",
    "START_TOKEN, END_TOKEN =[tokenizer.vocab_size],[tokenizer.vocab_size+1]\n",
    "VOCAB_SIZE=tokenizer.vocab_size+2\n",
    "print('임의 질문 샘플 정수 인코딩: {}'.format(tokenizer.encode(question[20])))\n",
    "\n",
    "# 문장의 최대 정수를 정해줌\n",
    "max_length=40\n",
    "def tokenize_and_filter(inputs,outputs):\n",
    "    tokenized_inputs, tokenized_outputs=[],[]\n",
    "    for(sentence1, sentence2) in zip(inputs,outputs):\n",
    "         # 인 코딩 시작, 종료 토큰 추가 \n",
    "        sentence1=START_TOKEN+tokenizer.encode(sentence1)+END_TOKEN\n",
    "        sentence2=END_TOKEN+tokenizer.encode(sentence2)+END_TOKEN\n",
    "        \n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "        \n",
    "        # 패딩\n",
    "        tokenized_inputs=tf.keras.preprocessing.sequence.pad_sequences(tokenized_inputs, maxlen=max_length,padding='post')\n",
    "        tokenized_outputs=tf.keras.preprocessing.sequence.pad_sequences(tokenized_outputs, maxlen=max_length, padding='post')\n",
    "        \n",
    "        return tokenized_inputs, tokenized_outputs\n",
    "    \n",
    "question,answers=tokenize_and_filter(question, answers)\n",
    "print(question[0])\n",
    "\n",
    "dataset=tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs':question,\n",
    "        'dec_inputs':answers[:,:-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs':answers[:,1:]\n",
    "    }\n",
    "\n",
    "))\n",
    "\n",
    "dataset=dataset.cache()\n",
    "dataset=dataset.shuffle(buffer_size)\n",
    "dataset=dataset.batch(batch_size)\n",
    "dataset=dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# 트랜스 포머 모델\n",
    "def transformer(vocab_size, num_layers, dff, d_model, num_heads, dropout, name=\"transformer\"):\n",
    "    # 인코더에 입력\n",
    "    inputs=tf.keras.Input(shape=(None,),name=\"inputs\")\n",
    "    # 디코더에 입력\n",
    "    dec_inputs=tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "    \n",
    "    enc_padding_mask=tf.keras.layers.Lambda(create_padding_mask, output_shape=(1,1,None),\n",
    "                                           name=\"enc_padding_mask\")(inputs)\n",
    "    \n",
    "    look_ahead_mask=tf.keras.layers.Lambda(create_look_ahead_mask, output_shape=(1,None,None),name='look_ahead_mask'),(dec_inputs)\n",
    "    \n",
    "    dec_padding_mask=tf.keras.layers.Lambda(create_padding_mask, output_shape=(1,1,None),name=\"dec_padding_mask\")(inputs)\n",
    "    \n",
    "    enc_outputs=encoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff, d_model=d_model, num_heads=num_heads, dropout=dropout,)(inputs=[inpputs,enc_padding_mask])\n",
    "    \n",
    "    dec_outputs=decoder(vocab_size=vocab_size, num_layers=num_layers, dff=dff, d_model=d_model, num_heads=num_heads, dropout=dropout,)(inputs=[dec_inputs, enc_outputs,look_ahead_mask, dec_padding_mask])\n",
    "    \n",
    "    outputs-tf.keras.layers.Dense(units=vocab_size,name=\"outputs\")(dec_outputs)\n",
    "    \n",
    "    return tf.keras.Model(input=[inputs, dec_inputs],outputs=outputs, name=name)\n",
    "\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, position, kd_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding=self.positional_encoding(position, d_model)\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles=1/tf.pow(10000,(2*(i//2))/tf.cast(d_model,tf.float32))\n",
    "        return position * angles\n",
    "    def positional_encoding(self,position, d_model):\n",
    "        angle_rads=self.get_angles(position=tf.range(position, dtype=tf.float32)[:,tf.newaxis],i=tf.range(d_model, dtype=tf.float32)[tf.newaxis,:],d_model=d_model)\n",
    "        # 짝수에는 사인 함수 적용\n",
    "        sines=tf.math.sin(angle_rads[:,0::2])\n",
    "        # 홀수에는 코사인 함수 적용\n",
    "        cosines=tf.math.cos(angle.rads[:,1::2])\n",
    "        \n",
    "        angle_rads=np.zeros(angle_rads.shape)\n",
    "        angle_rads[:,0::2]=sines\n",
    "        angle_rads[:,1::2]=cosines\n",
    "        \n",
    "        pos_encoding=tf.constant(angle_rads)\n",
    "        pos_encoding=pos_encoding[tf.newaxis,...]\n",
    "        print(pos_encoding.shape)\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    def call(self, inputs):\n",
    "        return inputs+self.pos_encoding[:,:tf.shape(inputs)[1],:]\n",
    "    def create_padding_mask(x):\n",
    "        mask=tf.cast(tf.math.equal(x,0),tf.float32)\n",
    "        return  mask[:tf.newaxis, tf.newaxis, :]\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c306bcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a857dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
